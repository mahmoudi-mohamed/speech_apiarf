import subprocess
import sys
import os
import glob
import shutil
import json
from pathlib import Path

print("="*60)
print("ğŸ”§ ONNX Export - Final Fix")
print("="*60)

# Step 1: Verify PyTorch
print("
[1/6] Verifying PyTorch...")
result = subprocess.run([sys.executable, "-c", "import torch; print(torch.__version__)"],
                       capture_output=True, text=True)
if result.returncode == 0:
    pytorch_version = result.stdout.strip()
    print(f"âœ“ PyTorch {pytorch_version}")
else:
    print("âŒ PyTorch not found.")
    sys.exit(1)

# Step 2: Ensure piper.train module is installed
print("
[2/6] Setting up piper.train module...")

# Define the piper directory
piper_dir = '/content/piper1-gpl'

# Clone if not exists
if not os.path.exists(piper_dir):
    print("Piper repository not found, cloning...")
    subprocess.run(
        'git clone -q https://github.com/OHF-Voice/piper1-gpl.git /content/piper1-gpl',
        shell=True, check=True
    )
    print("âœ“ Repository cloned")

# Change into the piper directory
os.chdir(piper_dir)

result = subprocess.run([
    sys.executable, "-c", "import piper.train; print('Already installed')"
], capture_output=True, text=True)

if "Already installed" not in result.stdout:
    print("Installing piper.train module...")
    result = subprocess.run([
        sys.executable, "-m", "pip", "install", "-q", "-e", ".[train]"
    ], capture_output=True, text=True)
    if result.returncode == 0:
        print("âœ“ piper.train module installed")
    else:
        print(f"âŒ Failed to install piper.train: {result.stderr}")
        sys.exit(1)
else:
    print("âœ“ piper.train module already available")

# Step 3: Find checkpoint
print("
[3/6] Finding checkpoint...")

# --- MODIFIED: Use user-specified checkpoint path and epoch ---
checkpoint_dir_from_drive = "/content/drive/MyDrive/piper_tts_backup/training_output/lightning_logs/version_0/checkpoints"

# Ensure we are in a neutral directory before looking for files in a specific path
original_cwd = os.getcwd()
os.chdir('/content') # Change to a known directory to avoid issues with previous os.chdir

all_checkpoints_in_dir = sorted(glob.glob(os.path.join(checkpoint_dir_from_drive, "*.ckpt")))

latest = None
# MODIFIED: Removed explicit epoch filter, now takes the last (latest) checkpoint found
if all_checkpoints_in_dir:
    latest = all_checkpoints_in_dir[-1] # Get the last checkpoint (most recent epoch)

if not latest:
    print(f"âŒ No checkpoint found in {checkpoint_dir_from_drive}!")
    sys.exit(1)

print(f"âœ“ Found checkpoint: {os.path.basename(latest)}")

# Step 4: Prepare output
print("
[4/6] Preparing output directory...")
os.makedirs('/content/output', exist_ok=True)
output_path = "/content/output/my_voice.onnx"

# Step 5: Create ONNX export script with proper device handling
print("
[5/6] Creating export script with device handling...")

export_script = f'''
import sys
import torch
import torch.onnx

# Add piper to path
sys.path.insert(0, '/content/piper1-gpl/src')

print("Loading model from checkpoint...")
from piper.train.vits.lightning import VitsModel

# Load model
model = VitsModel.load_from_checkpoint("{latest}")

# Move model to CPU for export (required for ONNX export)
print("Moving model to CPU for export...")
model = model.to('cpu')
model.eval()

print("Model loaded and ready")

# Get model config
if hasattr(model, 'config'):
    n_vocab = model.config.get('num_symbols', 256)
else:
    n_vocab = 256

# Create dummy inputs ON CPU
batch_size = 1
seq_length = 50
dummy_phoneme_ids = torch.randint(0, n_vocab, (batch_size, seq_length), dtype=torch.long)
dummy_phoneme_lengths = torch.tensor([seq_length], dtype=torch.long)
dummy_scales = torch.tensor([0.667, 1.0, 0.8], dtype=torch.float32)

print(f"Input shapes:")
print(f"  phoneme_ids: {{dummy_phoneme_ids.shape}} (device: {{dummy_phoneme_ids.device}})")
print(f"  phoneme_lengths: {{dummy_phoneme_lengths.shape}} (device: {{dummy_phoneme_lengths.device}})")
print(f"  scales: {{dummy_scales.shape}} (device: {{dummy_scales.device}})")

print("
Exporting to ONNX (this may take 1-2 minutes)...")

# Export with torch.onnx.export
try:
    with torch.no_grad():
        torch.onnx.export(
            model,
            (dummy_phoneme_ids, dummy_phoneme_lengths, dummy_scales),
            "{output_path}",
            export_params=True,
            opset_version=11, # Changed to 11 for compatibility
            do_constant_folding=True,
            input_names=['input', 'input_lengths', 'scales'],
            output_names=['audio'],
            dynamic_axes={{
                'phoneme_ids': {{0: 'batch_size', 1: 'phoneme_length'}},
                'phoneme_lengths': {{0: 'batch_size'}},
                'audio': {{0: 'batch_size', 1: 'audio_length'}}
            }},
            verbose=False
        )

    print("âœ… ONNX export completed successfully!")

    # Verify the file
    import os
    if os.path.exists("{output_path}"):
        size = os.path.getsize("{output_path}") / (1024*1024)
        print(f"âœ… Output file created: {{size:.1f}} MB")
    else:
        print("âŒ Output file was not created")
        sys.exit(1)

except Exception as e:
    print(f"âŒ Export failed: {{e}}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
'''

export_script_path = '/content/onnx_export_fixed.py'
with open(export_script_path, 'w') as f:
    f.write(export_script)

print("âœ“ Export script created")

# Step 6: Execute the export
print("
[6/6] Executing ONNX export...")
print("â³ This will take 1-3 minutes...
")

result = subprocess.run(
    [
        sys.executable, export_script_path
    ],
    capture_output=True,
    text=True,
    cwd='/content' # Execute from /content
)

# Show output
if result.stdout:
    print(result.stdout)

# Show errors if any
if result.returncode != 0:
    print("
âŒ Export failed")
    if result.stderr:
        error_lines = result.stderr.split('
')
        # Show last 20 lines of error
        print("Error details:")
        for line in error_lines[-20:]:
            if line.strip():
                print(f"  {line}")

# Verify and finalize
print("
" + "="*60)
print("ğŸ“‹ Final Verification")
print("="*60)

if os.path.exists(output_path):
    size_mb = os.path.getsize(output_path) / (1024*1024)

    if size_mb > 0.5:  # At least 500KB
        print(f"
âœ… ONNX model successfully created!")
        print(f"   Size: {size_mb:.1f} MB")

        # Handle config file
        config_paths = [
            '/content/my_voice/config.json',
            '/content/training_output/config.json'
        ]

        config_output = '/content/output/my_voice.onnx.json'
        config_found = False

        for config_path in config_paths:
            if os.path.exists(config_path):
                shutil.copy(config_path, config_output)
                print(f"âœ… Config file copied")
                config_found = True
                break

        if not config_found:
            print("Creating config file...")
            minimal_config = {
                "audio": {
                    "sample_rate": 22050,
                    "filter_length": 1024,
                    "hop_length": 256,
                    "win_length": 1024
                },
                "inference": {
                    "noise_scale": 0.667,
                    "length_scale": 1.0,
                    "noise_w": 0.8
                },
                "espeak": {
                    "voice": "ar"
                },
                "phoneme_id_map": {}
            }

            with open(config_output, 'w') as f:
                json.dump(minimal_config, f, indent=2)

            print("âœ… Config file created")

        # Success message
        print("
" + "="*60)
        print("ğŸ‰ SUCCESS! YOUR MODEL IS READY!")
        print("="*60)

        print("
ğŸ“ Model files:")
        print(f"   ğŸ“„ my_voice.onnx ({size_mb:.1f} MB)")
        print(f"   ğŸ“„ my_voice.onnx.json")

        print("
ğŸ“‚ Location:")
        print("   /content/output/")

        print("
ğŸ’¡ Next steps:")
        print("   1. Test your voice in the next cell")
        print("   2. Download both files")
        print("   3. Use with Piper TTS!")

        print("
ğŸ“ How to use with Piper:")
        print("   echo 'Your text here' | piper ")
        print("     --model my_voice.onnx ")
        print("     --config my_voice.onnx.json ")
        print("     --output_file output.wav")

    else:
        print(f"
âš ï¸  File too small: {size_mb:.3f} MB")
        print("Export may have failed")
else:
    print("
âŒ ONNX file was not created")
    print("
The export failed. This could be due to:")
    print("  1. Model architecture incompatibility")
    print("  2. Memory issues")
    print("  3. Corrupted checkpoint")

    print(f"
ğŸ“ Your checkpoint is safe at:")
    print(f"   {latest}")

    print("
ğŸ’¡ You can try:")
    print("   1. Restart runtime and re-run all cells")
    print("   2. Download checkpoint and export locally")