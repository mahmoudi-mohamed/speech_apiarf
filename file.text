import subprocess
import sys
import os
import glob
import shutil
import json
from pathlib import Path

print("="*60)
print("ğŸ”§ ONNX Export - Final Fix")
print("="*60)

# Step 1: Verify PyTorch
print("\\n[1/6] Verifying PyTorch...")
result = subprocess.run([sys.executable, "-c", "import torch; print(torch.__version__)"],
                       capture_output=True, text=True)
if result.returncode == 0:
    pytorch_version = result.stdout.strip()
    print(f"âœ“ PyTorch {{pytorch_version}}")
else:
    print("âŒ PyTorch not found.")
    sys.exit(1)

# Step 2: Ensure piper.train module is installed
print("\\n[2/6] Setting up piper.train module...")

# Define the piper directory
piper_dir = '/content/piper1-gpl'

# Clone if not exists
if not os.path.exists(piper_dir):
    print("Piper repository not found, cloning...")
    subprocess.run(
        'git clone -q https://github.com/OHF-Voice/piper1-gpl.git /content/piper1-gpl',
        shell=True, check=True
    )
    print("âœ“ Repository cloned")

# Change into the piper directory
os.chdir(piper_dir)

result = subprocess.run([
    sys.executable, "-c", "import piper.train; print('Already installed')"
], capture_output=True, text=True)

if "Already installed" not in result.stdout:
    print("Installing piper.train module...")
    result = subprocess.run([
        sys.executable, "-m", "pip", "install", "-q", "-e", ".[train]"
    ], capture_output=True, text=True)
    if result.returncode == 0:
        print("âœ“ piper.train module installed")
    else:
        print(f"âŒ Failed to install piper.train: {{result.stderr}}")
        sys.exit(1)
else:
    print("âœ“ piper.train module already available")

# Step 3: Find checkpoint
print("\\n[3/6] Finding checkpoint...")

# --- MODIFIED: Use user-specified checkpoint path and epoch ---
checkpoint_dir_from_drive = "/content/drive/MyDrive/piper_tts_backup/training_output/lightning_logs/version_0/checkpoints"

# Ensure we are in a neutral directory before looking for files in a specific path
original_cwd = os.getcwd()
os.chdir('/content') # Change to a known directory to avoid issues with previous os.chdir

all_checkpoints_in_dir = sorted(glob.glob(os.path.join(checkpoint_dir_from_drive, "*.ckpt")))

latest = None
# MODIFIED: Removed explicit epoch filter, now takes the last (latest) checkpoint found
if all_checkpoints_in_dir:
    latest = all_checkpoints_in_dir[-1] # Get the last checkpoint (most recent epoch)

if not latest:
    print(f"âŒ No checkpoint found in {{checkpoint_dir_from_drive}}!")
    sys.exit(1)

print(f"âœ“ Found checkpoint: {{os.path.basename(latest)}}")

# Step 4: Prepare output
print("\\n[4/6] Preparing output directory...")
os.makedirs('/content/output', exist_ok=True)
output_path = "/content/output/my_voice.onnx"
config_output_path = "/content/output/my_voice.onnx.json" # Define config path here

# Step 5: Create ONNX export script with proper device handling
print("\\n[5/6] Creating export script with device handling...")

export_script = f'''
import sys
import torch
import torch.onnx
import os
import shutil
import json
from pathlib import Path

# Add piper to path
sys.path.insert(0, '/content/piper1-gpl/src')

print("Loading model from checkpoint...")
from piper.train.vits.lightning import VitsModel

# Load model
model = VitsModel.load_from_checkpoint("{latest}")

# Move model to CPU for export (required for ONNX export)
print("Moving model to CPU for export...")
model = model.to('cpu')
model.eval()

print("Model loaded and ready")

# Get model config
if hasattr(model, 'config'):
    n_vocab = model.config.get('num_symbols', 256)
else:
    n_vocab = 256

# Create dummy inputs ON CPU
batch_size = 1
seq_length = 50
dummy_phoneme_ids = torch.randint(0, n_vocab, (batch_size, seq_length), dtype=torch.long)
dummy_phoneme_lengths = torch.tensor([seq_length], dtype=torch.long)
dummy_scales = torch.tensor([0.667, 1.0, 0.8], dtype=torch.float32)

print(f"Input shapes:")
print(f"  phoneme_ids: {{dummy_phoneme_ids.shape}} (device: {{dummy_phoneme_ids.device}})")
print(f"  phoneme_lengths: {{dummy_phoneme_lengths.shape}} (device: {{dummy_phoneme_lengths.device}})")
print(f"  scales: {{dummy_scales.shape}} (device: {{dummy_scales.device}})")

print("\\nExporting to ONNX (this may take 1-2 minutes)...")

# Export with torch.onnx.export
try:
    with torch.no_grad():
        torch.onnx.export(
            model,
            (dummy_phoneme_ids, dummy_phoneme_lengths, dummy_scales),
            "{output_path}",
            export_params=True,
            opset_version=11, # Changed to 11 for compatibility
            do_constant_folding=True,
            input_names=['input', 'input_lengths', 'scales'],
            output_names=['audio'],
            dynamic_axes={{
                'phoneme_ids': {{0: 'batch_size', 1: 'phoneme_length'}},
                'phoneme_lengths': {{0: 'batch_size'}},
                'audio': {{0: 'batch_size', 1: 'audio_length'}}
            }},
            verbose=False
        )

    print("âœ… ONNX export completed successfully!")

    # Verify the ONNX file
    if os.path.exists("{output_path}"):
        size = os.path.getsize("{output_path}") / (1024*1024)
        print(f"âœ… Output ONNX file created: {{size:.1f}} MB")
    else:
        print("âŒ Output ONNX file was not created")
        sys.exit(1)

    # Handle config file for ONNX
    config_paths = [
        '/content/my_voice/config.json', # Placeholder path for original config
        '/content/training_output/config.json' # Placeholder path for original config
    ]
    
    # Use the config output path defined in the main script
    config_output = "{config_output_path}" 
    config_found_from_source = False

    for config_path in config_paths:
        if os.path.exists(config_path):
            shutil.copy(config_path, config_output)
            print(f"âœ… Config file copied from {{config_path}}")
            config_found_from_source = True
            break

    if not config_found_from_source:
        print("Creating minimal config file...")
        minimal_config = {{
            "audio": {{
                "sample_rate": 22050,
                "filter_length": 1024,
                "hop_length": 256,
                "win_length": 1024
            }},
            "inference": {{
                "noise_scale": 0.667,
                "length_scale": 1.0,
                "noise_w": 0.8
            }},
            "espeak": {{
                "voice": "ar"
            }},
                            "phoneme_id_map": {{}},
                            "num_symbols": n_vocab,
                            "num_speakers": 1 # Use calculated n_vocab
        }}

        with open(config_output, 'w') as f:
            json.dump(minimal_config, f, indent=2)

        print("âœ… Minimal config file created")
    
    # Final check for config file existence
    if not os.path.exists(config_output):
        print("âŒ Config file was NOT created after all attempts.")
        sys.exit(1)


except Exception as e:
    print(f"âŒ Export failed: {{e}}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
'''

export_script_path = '/content/onnx_export_fixed.py'
with open(export_script_path, 'w') as f:
    f.write(export_script)

print("âœ“ Export script created")

# Step 6: Execute the export
print("\\n[6/6] Executing ONNX export...")
print("â³ This will take 1-3 minutes...\\n")

result = subprocess.run(
    [
        sys.executable, export_script_path
    ],
    capture_output=True,
    text=True,
    cwd='/content' # Execute from /content
)

# Show output
if result.stdout:
    print(result.stdout)

# Show errors if any
if result.returncode != 0:
    print("\\nâŒ Export failed")
    if result.stderr:
        error_lines = result.stderr.split('\\n')
        # Show last 20 lines of error
        print("Error details:")
        for line in error_lines[-20:]:
            if line.strip():
                print(f"  {{line}}")
    sys.exit(1) # Exit if export script failed

# Verify and finalize
print("\\n" + "="*60)
print("ğŸ“‹ Final Verification")
print("="*60)

if os.path.exists(output_path):
    size_mb = os.path.getsize(output_path) / (1024*1024)

    if size_mb > 0.5:  # At least 500KB
        # Check for config file as well
        if os.path.exists(config_output_path):
            print(f"\\nâœ… ONNX model successfully created!")
            print(f"   Size: {{size_mb:.1f}} MB")
            print(f"âœ… Config file created: {{config_output_path}}")

            # Success message
            print("\\n" + "="*60)
            print("ğŸ‰ SUCCESS! YOUR MODEL IS READY!")
            print("="*60)

            print("\\nğŸ“ Model files:")
            print(f"   ğŸ“„ my_voice.onnx ({{size_mb:.1f}} MB)")
            print(f"   ğŸ“„ my_voice.onnx.json")

            print("\\nğŸ“‚ Location:")
            print("   /content/output/")

            print("\\nğŸ’¡ Next steps:")
            print("   1. Test your voice in the next cell")
            print("   2. Download both files")
            print("   3. Use with Piper TTS!")

            print("\\nğŸ“ How to use with Piper:")
            print("   echo 'Your text here' | piper \\")
            print("     --model my_voice.onnx \\")
            print("     --config my_voice.onnx.json \\")
            print("     --output_file output.wav")

        else:
            print("âŒ Config file was not created by the export script.")
            sys.exit(1)

    else:
        print(f"\\nâš ï¸  File too small: {{size_mb:.3f}} MB")
        print("Export may have failed")
        sys.exit(1) # Exit if ONNX file is too small
else:
    print("\\nâŒ ONNX file was not created by the export script.")
    print("\\nThe export failed. This could be due to:")
    print("  1. Model architecture incompatibility")
    print("  2. Memory issues")
    print("  3. Corrupted checkpoint")

    print(f"\\nğŸ“ Your checkpoint is safe at:")
    print(f"   {{latest}}")

    print("\\nğŸ’¡ You can try:")
    print("   1. Restart runtime and re-run all cells")
    print("   2. Download checkpoint and export locally")
    sys.exit(1) # Exit if ONNX file not created