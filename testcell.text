# ========================================
# CELL 8 - UPDATED AND FIXED
# Copy everything below this line into your Cell 8
# ========================================

"""
Step 8: Test Your Model - FIXED VERSION

Properly configures wave files with correct audio parameters.
"""

import subprocess
import sys
import os
from pathlib import Path

print("="*60)
print("ğŸ¤ Testing Your Custom Voice Model")
print("="*60)

# Step 1: Install piper-tts Python library from local source
print("\\n[1/4] Installing piper-tts library from local source...")
result = subprocess.run([
    sys.executable, "-m", "pip", "install", "-q", "-e", "/content/piper1-gpl"
], capture_output=True, text=True)

if result.returncode == 0:
    print("âœ“ piper-tts installed from local source")
else:
    print(f"âŒ Failed to install piper-tts from local source: {{result.stderr}}")
    sys.exit(1)

# Ensure piper source is in sys.path for local module discovery (redundant with -e install)
# sys.path.insert(0, '/content/piper1-gpl/src')

# Step 2: Verify model files exist
print("\\n[2/4] Checking for model files...")
model_path = "/content/output/my_voice.onnx"
config_path = "/content/output/my_voice.onnx.json"

if not os.path.exists(model_path):
    print("âŒ Model file not found!")
    print(f"   Expected: {{model_path}}")
    print("\\nğŸ’¡ Make sure you've completed Step 7 (Export to ONNX)")
    sys.exit(1)

print(f"âœ“ Model found: {{os.path.basename(model_path)}}")

if not os.path.exists(config_path):
    print("âš ï¸  Config file not found, model may still work")
else:
    print(f"âœ“ Config found: {{os.path.basename(config_path)}}")

# Step 3: Generate test audio samples
print("\\n[3/4] Generating test audio samples...")
print("â³ This may take a few seconds...\\n")

# Create test directory
os.makedirs('/content/test_audio', exist_ok=True)

# Test sentences (ADAPTED FOR ARABIC)
test_sentences = [
    "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ù‡Ø°Ø§ Ù‡Ùˆ ØµÙˆØªÙŠ Ø§Ù„Ù…Ø®ØµØµ Ø§Ù„Ù…Ø¯Ø±Ø¨.",
    "Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ Ø¨Ø¥ÙŠÙ‚Ø§Ø¹ ÙˆÙ†Ø¨Ø±Ø© Ù…Ù†Ø§Ø³Ø¨Ø©.",
    "ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… Ù„Ù… ÙŠÙƒÙ† Ø£Ø³Ù‡Ù„ Ù…Ù† Ø£ÙŠ ÙˆÙ‚Øª Ù…Ø¶Ù‰ Ù…Ø¹ Ø¨Ø§ÙŠØ¨Ø± ØªÙŠ ØªÙŠ Ø¥Ø³."
]

# Import piper after installation
from piper.voice import PiperVoice
import wave
import io

try:
    # Load the model
    print("Loading model...")
    voice = PiperVoice.load(model_path, use_cuda=False)
    print(f"âœ“ Model loaded successfully")
    print(f"  Sample rate: {{voice.config.sample_rate}} Hz")
    print(f"  Channels: {{voice.config.num_channels if hasattr(voice.config, 'num_channels') else 1}}")

    # Generate audio for each test sentence
    generated_files = []

    for i, text in enumerate(test_sentences, 1):
        output_file = f"/content/test_audio/test_{i}.wav"

        print(f"\\n  Generating test {{i}}/{{len(test_sentences)}}: '{{text[:50]}}...'")

        # Use voice.synthesize_wav to ensure proper WAV file creation
        voice.synthesize_wav(text, output_file)

        if os.path.exists(output_file):
            size_kb = os.path.getsize(output_file) / 1024
            print(f"  âœ“ Created: test_{i}.wav ({{size_kb:.1f}} KB)")
            generated_files.append(output_file)
        else:
            print(f"  âŒ Failed to create test_{i}.wav")

    # Step 4: Display audio player
    print("\\n" + "="*60)
    print("âœ… SUCCESS! Voice Model is Working!")
    print("="*60)

    if generated_files:
        print(f"\\nğŸ§ Generated {{len(generated_files)}} audio samples")
        print("\\nğŸ“ Audio files:")
        for filepath in generated_files:
            print(f"   {{filepath}}")

        print("\\n" + "="*60)
        print("ğŸ”Š LISTEN TO YOUR VOICE:")
        print("="*60)

        # Display audio players for Colab
        from IPython.display import Audio, display, HTML

        for i, (filepath, text) in enumerate(zip(generated_files, test_sentences), 1):
            print(f"\\nSample {{i}}: '{{text}}'")
            display(Audio(filepath, autoplay=False))

        print("\\n" + "="*60)
        print("ğŸ’¡ Next Steps:")
        print("="*60)
        print("1. Download your model files:")
        print("   - /content/output/my_voice.onnx")
        print("   - /content/output/my_voice.onnx.json")
        print("\\n2. Use your model locally with:")
        print("   pip install piper-tts")
        print('   echo "Hello world" | piper -m my_voice.onnx --output_file output.wav')
        print("\\n3. Or use in Python:")
        print("   from piper.voice import PiperVoice")
        print("   import wave, io")
        print("   ")
        print("   voice = PiperVoice.load('my_voice.onnx')")
        print("   audio = io.BytesIO()")
        print("   ")
        print("   with wave.open(audio, 'wb') as wav:")
        print("       wav.setnchannels(1)")
        print("       wav.setsampwidth(2)")
        print("       wav.setframerate(voice.config.sample_rate)")
        print("       voice.synthesize('Hello!', wav)")

        print("\\nğŸ‰ Congratulations! Your custom voice is ready to use!")

    else:
        print("\\nâš ï¸  No audio files were generated")
        print("Check for errors above")

except Exception as e:
    print("\\n" + "="*60)
    print("âŒ Error Testing Model")
    print("="*60)
    print(f"\\nError: {{str(e)}}")
    print("\\nPossible causes:")
    print("  1. Model file is corrupted or incomplete")
    print("  2. piper-tts library not properly installed")
    print("  3. ONNX model export had issues")
    print("\\nDebugging steps:")
    print(f"  1. Check model size: {{os.path.getsize(model_path)/(1024*1024):.1f}} MB")
    print("  2. Re-run Step 7 (Export to ONNX)")
    print("  3. Verify training completed successfully in Step 6")

    import traceback
    print("\\nFull error details:")
    traceback.print_exc()